# Cloud Computing Lab 7

`mkdir lab7 && cd lab7`

## 1 Install Java and Hadoop

### Install Java

1. `sudo apt install default-jdk default-jre`

### Install Hadoop

1. `cd eclipse/`
2. Download Hadoop
   1. `sudo wget https://archive.apache.org/dist/hadoop/core/hadoop-2.7.3/hadoop-2.7.3.tar.gz`
3. Extract .tar
   1. `sudo tar -xvzf hadoop*`
4. Delete .tar
   1. `sudo rm hadoop*.tar.gz`
5. Rename folder
   1. `sudo mv hadoop-2.7.3 hadoop`

### Setup bash exports

1. Export Java
   1. `export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64`
   2. `echo $JAVA_HOME`
   3. `echo $PATH`

2. Export Hadoop
   1. `export HADOOP_HOME=/home/<username>/eclipse/hadoop`
   2. `export PATH=$PATH:$HADOOP_HOME/bin`
   3. `echo $HADOOP_HOME`
   4. `echo $PATH`

### Verify installations

1. Java
   1. `java --version`
2. Hadoop
   1. `hadoop version`

## 2 Setup and Write MapReduce in Eclipse IDE

In Eclipse IDE

1. Create a new Java Project
   1. Click *File*, *New* and *Java Project*
2. Name the project "Hadoop"
3. Ensure that JavaSE-1.7 is selected for the execution environment JRE
4. Click *Finish* and *Don't Create*
5. Right click *JRE System Library*, *Build Path* and *Configure*
6. Click *Add External JARs*
7. Add the following JAR files
   1. `/home/<username>/eclipse/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar`
   2. `/home/<username>/eclipse/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar`
8. Click *Apply and Close*
9. In `src` directory, create 3 new packages called:
   1. `average`
   2. `units`
   3. `wcount`
10. Copy the sample code into the associated packages and copy the inputs into the Hadoop directory
11. Run each package as a Java Application. Do not worry if you get exceptions, this is normal
    1. Right click package, *Run as*, *Java Application*
12. Export each package as a .jar file
    1. Right click package, *Export*, *Java -> Runnable JAR file*
13. Assign Launch Configuration the same as the package you are currently exporting
14. Set the export destination to the `lab7` directory and name the JAR the same as the package (example: `units.jar`)
15. Copy all the generated `.jar` files into the hadoop directory.
16. Create an `input` directory inside the hadoop directory

### Run the first project

1. Move to the hadoop directory
   1. `cd /home/<username>/eclipse/hadoop/`
2. Copy `sample1.txt` into the `input` directory
3. Run the project
   1. `hadoop jar units.jar input output`
4. Check the output directory and files
   1. `ls output/`
   2. `cat output/part-*`
5. Remove `output` directory

### Run the second project

1. Move to the hadoop directory
   1. `cd /home/<username>/eclipse/hadoop/`
2. Copy `employee_records.txt` into the `input` directory
3. Run the project
   1. `hadoop jar average.jar input output`
4. Check the output directory and files
   1. `ls output/`
   2. `cat output/part-*`
5. Remove `output` directory

### Run the third project

1. Move to the hadoop directory
   1. `cd /home/<username>/eclipse/hadoop/`
2. Copy `alice.txt` into the `input` directory
3. Run the project
   1. `hadoop jar wcount.jar input output`
4. Check the output directory and files
   1. `ls output/`
   2. `cat output/part-*`
5. Remove `output` directory

## 3 Amazon Elastic MapReduce

### Preperations

In AWS Console

1. Click *Services* and *S3*
2. Create a new bucket with the following details
   1. Name: `<username>-lab7-bucket`
   2. Region: N. Virginia
   3. *Next*
   4. *Next*
   5. Untick *Block all public access* and confirm that you are aware of the security risks
   6. *Create Bucket*
3. Select lab7 bucket and create two folders called `code` and `input`
4. Upload wcount.jar to the `code` folder
   1. *Next*, *Next*, *Upload*
5. Copy all the text from the following link, save it to a file called `alice30.txt` and upload it into `input` folder
   1. <http://www.umich.edu/~umfandsf/other/ebooks/alice30.txt>
   2. *Next*, *Next*, *Upload*

### Create Amazon MapReduce Cluster

In AWS Console

1. Click *Services* and *EMR* under *Analytics*
2. Click *Create Cluster*
3. Create a cluster with the following details:
   1. Name: `s3668468-lab7-cluster`
   2. S3 Folder: *browse for lab7 bucket*
   3. Launch Mode: *Step execution*
   4. Release: `emr-5.5.0`
   5. Step type: *Custom JAR* and *Configure*
      1. Location: `s3://s3668468-lab7-bucket/code/wcount.jar`
      2. Arguments: `s3://s3668468-lab7-bucket/input` and `s3://s3668468-lab7-bucket/output1`
      3. Action: Terminate cluster
      4. Click *Add*
   6. Security Access: *Default*
   7. Click *Create Cluster*

### View Results

In AWS Console

1. Go to *Services* and *S3*
2. Click on the lab7 bucket
3. Go into the outputs folder (this folder is generated by EMR)
4. Download all files and check the word count for `alice30.txt`
